# 线性模型

从线性模型开始

3.1基本形式

> 给定由d个属性描述的示例 **x = （x1,x2,...xd）**,其中**xi**是**x**在第**i**个属性上的取值，线性模型试图学得一个通过属性的线性组合来进行预测的函数，即

**f(x) = w1x1+w2x2+...+wdxd+b**

> 一般用向量形式写成
>
> 

**f(x) = wTx+b**

> 其中 w = (w1,w2,...wd). **w**和**d**学得之后，模型就得以确定。

- 线性模型**形式简单，易于建模**，但却蕴含着机器学习中一些重要的基本思想

- 许多功能更为强大的非线性模型可在线性模型的基础上引入**层级结构或高维映射**而得

- w直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性。如若在西瓜问题中学得“f好瓜（x） = 0.2x色泽+0.5x根蒂+0.3x~敲声+1”，则意味着可以通过综合考虑色泽、根蒂，敲声来判断瓜好不好，其中根蒂最紧，而敲声比色泽更重要。

3.2线性回归

> 考虑最简单的情形:输入属性的数目只有一个，忽略关于属性的下标，即D = {（xi,yi）}i=1m,其中xi∈R。

- 若属性值之间存在“序”关系，则可通过连续化将其转化为连续值。

- 如二值属性"身高"的取值"高" "矮"可转化为 {1.0,0.0} ,

- 三值属性"高度" 的取值"高" "中" "低"可转化为 {1,0.5,0.0};

- 若属性值间不存在序关系，假定有k个属性值，则通常转化为k维向量，例如属性"瓜类"的取值"西瓜" "南瓜" "黄瓜"可转化为 (0,0,1) (0,1,0),(1,0,0).

线性回归试图学得：f(xi) = wxi +b ,使得 f(xi) ≈yi.如何确定w和b?在于如何衡量f(x)与y之间的差别.

均方误差是回归任务中最常用的性能度量，要试图**让均方误差最小化**

 

（**w\*,b\*表示w,b的解**）![651d9b60fe47496c8c1723e38c52651a](C:\Users\86187\Desktop\各种表格 文件\图标素材\651d9b60fe47496c8c1723e38c52651a.png)

- 基于均方误差最小化来进行模型求解的方法称为**最小二乘法**，在线性回归中，**最小二乘法**就是试图找到一条直线，使所有**样本到直线上的欧氏距离之和最小**。

  

- 求解w和b使![img](https://img-blog.csdnimg.cn/5a9344c697824356be3ecab636f46195.png)最小化的过程，成为**线性回归模型的最小二乘“参数估计”**。(**未知数只有w和b**)

- 将E（w,b）（**凸函数**，如y=x2）分别对w和b求导，![6b04ddd686bd5740b1c88e993a5b9a2f_720w](C:\Users\86187\Desktop\各种表格 文件\图标素材\6b04ddd686bd5740b1c88e993a5b9a2f_720w.jpg)得到

- 类似的，可以利用**最小二乘法**对**w**和**d**进行估计，把w和b吸收进入向量形式把数据集D表示为一个m×（d+1）大小的矩阵**X**，其中**每行对应一个示例**，该行前**d**个元素对应于示例的**d个属性值**，最后一个元素**恒置为1，**即

#### 其他定义：对数线性回归；广义线性模型
