 ## 统计学习及监督学习概论

- 监督学习方法：

是从标注中学习模型的机器学习问题，是统计学习机器学习的重要组成部分

### 统计学习/机器学习

- 概念：是关于计算机基于数据结构概率统计模型并运用模型对数据进行**预测**和**分析**的一门学科
- 特点：
  - 基于计算机
  - 以数据为研究对象
  - 目的是对数据进行预测和分析
  - 以方法为中心，统计学习方法**构建模型**并**应用模型**进行**预测**和**分析**
  - 是以概率论、统计学、信息论、计算理论、最优化理论以及计算机科学等的交叉学科
- 统计学习就是计算机系统运用**数据**和**统计方法**提高**系统性能**的机器学习
- 两种的区别与联系



![img](https://s2.loli.net/2022/05/21/E7xYr3tPmisvQgJ.png)




- 对象 ：数据
  
  
  
  - 从数据出发，提取数据的特征，抽象出数据的模型，再回归到对数据的预测和分析中去
  - 数据多种多样：数字 文字 图像 音频数据及其组合
  - 统计学习的**基本假设**是：同类数据具有一定的统计规律性（可以用概率统计来处理），对于训练数据要求是独立同分布的（IID）
  - 以变量（组）为数据，可以是连续的、离散的，利用数据**构建模型**对数据**分析预测**
  
- 目的：预测、分析
  - 预测：使计算机更智能化，使其某些性能提高
  - 分析：获得新知识，带来新发现
  - 两目地是通过**构建概率统计模型**（函数、条件概率）实现的
  - 提高效率 用什么模型 怎么样学习模型

- 方法：

  统计学习的组成：监督学习、无监督学习、强化学习等组成

  - 从给定的、有限的、用于学习的训练数据集合 出发，假设数据是独立同分布的IID
    - Independently identical distribution（独立同分布）指随机过程中，任何时刻的取值都为随机变量，如果这些随机变量服从同一分布，并且互相独立，那么这些随机变量是独立同分布
  -  并且假设要学习的模型属于某个**函数的集合**（很多个模型（方法）的集合），称为**假设空间**
  - 应用**评价标准**，从假设空间中选取一个最优模型，对已知、未知的训练数据、测试数据z1给定标准下一个**最优**的预测
  - 最优模型的选取有**算法实现**

 总结：方法包括假设空间、模型选择的准则、模型学习的算法即三要素：**模型、策略、算法**

- 步骤：实现机器学习的一般步骤
  - 一个有限的训练数据集合
  - 确定有可能的模型假设空间，即学习模型的集合
  - 确定模型选择的准则，即学习策略
  - 实现求最优解的算法，即学习的算法
  - 通过学习方法选择最优模型
  - 利用学校的最优模型对新数据进行预测或分析

- 监督学习：分类、回归

![img](https://s2.loli.net/2022/05/21/R8OMyblg5sdiXza.png)

- 作用
  - 处理海量数据
  - 计算机智能化的有效手段
  - 计算机科学的一个重要部分

### 统计学习的分类

##### 监督学习

- 基本介绍
  - 定义：指从**标注数据**中学习预测模型的机器学习问题 
  - 标注数据：表示输入输出的**对应关系**，预测模型对给定的输入产生相应的输出
  - 本质：是学习输入到输出的**映射规律**

- 1.输入空间、特征空间输出空间

  - 每个具体输入是一个实例，一般又**特征向量**表示
  - 所以特征向量存在的空间称为**特征空间**，空间的每一维对应一个特征
  - 有时候假设输入空间与特征空间
  - 有时候假设输入空间与特征空间维度系统的空间，不予区分
  - 有时候假设输入空间与特征空间为不同的空间，将实例从输入空间**映射**到特征空间上
  - 监督学习中，将输入输出看作是定义在输入（特征）空间与输出空间是的随机变量的取值 
  - 输入变量X，输出变量Y，具体取值x，y，变量可以是标量可以是向量，训练数据测试数据输入输出是成对出现，一个对也称样本点（sample）

  介绍

  - 输入输出为连续变量称为**回归问题**，为有限个离散变量称为**分类问题**，为变量序列的预测问题称为**标注问题**

- 2.联合概率分布

  - 监督学习假设输入输出的随机变量X和Y遵循联合变量分布P（X，Y）。P（X，Y）表示分布函数，或分布密度函数。
  - 训练数据和测试数据被看作是依联合概率分布P（X，Y）独立同分布IID产生的
  - 统计学习假设数据存在一定的统计规律，XY具有联合概率分布就是监督学习关于数据的基本假设

- 3.假设空间

  - 就是一个模型空间：y=kx+b   ，k和b的选择
  - 监督学习的目的：学习一个输入到输出的映射，这一映射由模型来表示
  - 模型属于由输入空间到输出空间的映射集合，此集合就是假设空间
  - 假设空间的确定意味着学习的范围的确定
  - 监督模型可以是概率模型也可以是非概率模型，由**条件概率**P（Y|X）或**决策函数**Y=f（x）表示

- 4.问题的形式化

  监督学习分为学习和预测两个过程，由学习系统和预测系统完成

![img](https://s2.loli.net/2022/05/21/ja86FgUBkvH7IKL.png)

 （x，y）样本点，x：输入的观测值（输入或实例），y输出的观测值（输出）

 通过学习（或者训练）得到一个模型，表示为 **条件概率分布**或**决策函数**，来描述输入和输出的映射关系



预测系统对于给定的测试样本集的输入![img](https://s2.loli.net/2022/05/21/m9wsXZ57SNFHQhY.png)

给出相应的输出y N+1（挑出最大概率值）

- 5.Bayesian learning（贝叶斯学习）

  - 在概率模型的学习推理中，利用贝叶斯定理，计算在**给定数据条件**下模型的条件概率，即**后验概率**，并利用此原理进行模型的估计

  - 并运用此原理进行模型的估计，以及对数据的预测。
  - 将模型、未观测要素及其参数用变量表示
  - 贝叶斯学习特点：使用模型的先验分布

  假设随机变量D表示数据，随机变量θ表示**模型参数**，使用公式计算后验概率

![img](https://s2.loli.net/2022/05/21/Ew6mGvfPuINULqc.png)

P(θ)是先验概率，P(D|θ)是似然函数

模型估计，是估计整个后验概率，通常取后验概率最大的模型，取后验概率最大得到极大似然估计

![img](https://s2.loli.net/2022/05/21/Jmz7c8BdaOTZYHh.png)

极大似然估计约等于贝叶斯估计

### 统计学习方法三要素

**概述：方法=模型+策略+算法**

##### 1. Model

监督学习中，模型就是所要学习的条件概率或决策函数。

模型的假设空间包含所有可能的条件概率分布或决策函数构成的集合

假设空间一般有无穷个

![img](https://s2.loli.net/2022/05/21/EF5CvQyoxXDfcMl.png)：决策函数假设空间     

![img](https://s2.loli.net/2022/05/21/2FNtVlUamTZB5wq.png)条件概率分布假设空间

F通常是有一个参数向量决定的函数族

##### 2.Strategy

学习方法按照特定的策略，学习或选择最优的模型

损失函数：策略

- 0-1损失函数![img](https://s2.loli.net/2022/05/21/paMuQTRogOn5UlA.png)真实值Y和预测值f(x)

  结果是损失值

- 平方损失函数![img](https://s2.loli.net/2022/05/21/NZEfmIDkblQpdhe.png)

  用的较多

- 绝对损失函数![img](https://s2.loli.net/2022/05/21/27jchBwH1M9TsU3.png)

  用的很少

- 对数损失函数（对数似然损失函数）![img](https://s2.loli.net/2022/05/21/GHCOsMSAVYX8Tip.png)

  也会经常用到



损失值越少，模型越好

因为模型的输入、输出（X，Y）是随机变量，遵循联合分布P(X,Y),所以损失期望是

![img](https://s2.loli.net/2022/05/21/uzifdkPvaLyEXA5.png)

风险函数或期望损失

理论上模型f(X)关于联合分布的平均意义下的损失，称为**风险函数**或**期望损失**





