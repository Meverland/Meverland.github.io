# 人工神经网络

- 一种分类算法

## 神经元模型

- 神经网络：是由具有适应性的简单单元组成的广泛并行互联的网络，通过调节各连接的权重值改变连接的强度，进而实现感知和判断，它的组织能模拟生物神经系统对真实世界物体所作出的交互反映。

- 最基本成分：神经元（neuron）模型，即简单神经元

- M-P神经元模型：

  - 输入：神经元接收到n个其他神经元传递过来的信号，通过**带权连接**传递

  - 加权计算总和与**阈值**比较，相减，得到信号数值：
    $$
    y_{i}=f(\sum_{i}w_{i}X_{i}-\theta)
    $$
  
- 输出：信号数值通过【**激活函数**】，产生神经元输出
  

  
- 一般激活函数为**挤压函数**（sigmoid）
  $$
  y=(x*w+b)
  $$
  x,w为矩阵

- 【**偏置**】；上下调整

## 感知机&多层网络

- （单层）感知机：由两层神经元组成，输入层X接收外界信号传递给输出层，输出层y即M-P神经元也称为“阈值逻辑单元”，能实现，**或与非**运算，或与非都是【**线性可分**】问题

- 一般的，给定训练数据集，权重w和阈值theta可以通过学习得到，w+theta可以合并

- 学习规则：
  $$
  w_{i}=w_{i}+\bigtriangleup w_{i}
  $$
  
  $$
    \bigtriangleup w_{i}=\eta (y-\hat y )x_{i}
  $$
  
  



eta在(0,1),称为学习率，即步伐，参数

-   感知机，只进行激活函数处理，只有一层功能神经元，学习能力很有限，而且只能解决线性可分问题，不能解决异或问题

  

- **多层网络**
- 【**多层前馈神经网络**】：每一层与下一层**全互联**，同层不存在连接，不存在环状结构
  - 【**隐层网络**】：输入不包括信号加工，隐层和输出负责函数处理
  
 -  总：神经网络的学习过程，就是通过训练数据调整神经元之间的“**连接权**”，以及每个功能单元的“**阈值**”

- 训练多层网络的方法：反向传播【**BP算法**】（back propagation ）80年代，做分类用的，数字识别
- 【反馈神经网络】



- **激活函数**（非线性）
  - 主要有**sigmoid函数**、**tanh函数**、**ReLu函数**
  - 激活函数的一般性质：非线性、可微性、单调性、输出值范围、归一化、计算简单

- 损失函数：依然是最小平方误差准则，欧式距离度量损失标准、 softmax分装器
  
- 也有很多种
  
- 学习率（学习步长）：每次更新参数的幅度

- 过拟合 ：指模型在训练集上预测好，在测试集上效果差

  防止：惩罚性成本函数

##  BP算法

推导：

https://sapfigure-1-1256773093.cos.ap-nanjing.myqcloud.com//muyi484B383D9299D28145A988B6905B351D.jpg



```python
#输入......
#1.在（0，1）内随机初始化所有连接权和阈值
repeat
  for all(xk,yk)属于D do
       根据1式求当前样本输出yk；
        根据式3计算层神经元梯度项gj；
        根据4计算隐层神经元的梯度项eh；
        根据其他推导式更新连接权和阈值
   end for 
until 停止条件
#输出 连接权与阈值确定的多层前馈神经网络
```

输入
$$
D=\{(x_{k},y_{k})\}_{k=1}^m
$$
以及学习率eta
$$
\eta
$$




