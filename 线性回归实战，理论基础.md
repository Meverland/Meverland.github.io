## 理论基础

注：加粗为向量

- **问题描述** ：给定d个属性描述的实例**x**(x1,x2,x3....xn),其中xi是**x**在在第i个属性上的取值，线性模型试图学得一个通过属性的线性组合来进行预测的函数即：

- **函数**：f(x)=w1x1+w2x2+w3x3+....+wnxnw+b;

- **向量形式**：f(x)=**w**的转置***x**+b

- **目的**：学得**w**和b

- **总思路**：已知训练数据：**x**，**y**—>机器（算法）—>（得到）—>规则(**w**,b)

- **算法**：

  - 数据集：{(**x1**,**y1**)...(**xn**,yn) } **** 每个**xi**和**yi**都是一个向量：x11，x12，x13... x1d

    ​                此处为n组数据                                                   此处为d个属性

  - 算出模型： (**x1,y1**)     x1=(x11,x12...x1d)     **w1x1**+b=**Y1**

    ​                    (**x2,y2**)     x2=(x21,x22...x2d)     **w2x2**+b=**Y2**

    ​                      .....

    ​                    (**xn,yn**)    xn=(xn1,xn2...xnd)     **wdxd**+b=**Yd**（Y预测值）

    试图学的的模型使得 Yi=f(xi)≈yi(实际值)
    
  - 方法 ：多元（变量）线性回归
    
    E=arg min[(y1-Y1)²+(y2-Y2)²+ ... +(yd-Yd)²]   ：**均方误差**对应”欧式距离“，最小二乘法
    
    求解w和d使E最小的过程称为*线性回归模型的最小二乘”参数估计“*
    
    > 注，arg mini：使这个式子最小时，参数的取值
    
    
    
    把x数集D转化为矩阵 X
    
    y数集写成向量**y**
    
    w和b吸收成向量 
    $$
    W_{}^{*}=(w,b)
    $$
    
    > 注：大写W为估计值,大写X为矩阵
    
    $$
    \\W_{}^{*}=arg min(y-XW){}{T}(y-XW){}{T}
    $$
    
    此公式为两矩阵相乘，即每一个相乘求使式子最小时的w，b
    
    
    
    下一步求导：两边对W求导得到式子
    $$
    2X{}^{T}(XW-y)
    $$
    
    
    **使得上式为0，可得W最优解的闭式解**
    
    推导得最终回归模型为
    $$
    f(X_i)=X_{i}^{T}(x_{}^{T}X)_{}^{-1}X_{}^{T}y
    $$
    
    > 第一个第二个Xi 是Xi的预测值（向量），后面的X是矩阵，y也是向量（提供的数集）

